From e6c582d811964fb84478f3505fe587bf22de4abd Mon Sep 17 00:00:00 2001
From: kcgen <1557255+kcgen@users.noreply.github.com>
Date: Fri, 26 Feb 2021 15:56:53 -0800
Subject: [PATCH 1/3] Use rwqueue instead of the Moody-queue in FluidSynth

---
 src/midi/midi_fluidsynth.cpp | 31 ++++++++++++++++---------------
 src/midi/midi_fluidsynth.h   | 11 +++++------
 2 files changed, 21 insertions(+), 21 deletions(-)

diff --git a/src/midi/midi_fluidsynth.cpp b/src/midi/midi_fluidsynth.cpp
index cbfee2092..530de8baa 100644
--- a/src/midi/midi_fluidsynth.cpp
+++ b/src/midi/midi_fluidsynth.cpp
@@ -174,7 +174,8 @@ static std::string find_sf_file(const std::string &name)
 }
 
 MidiHandlerFluidsynth::MidiHandlerFluidsynth()
-        : soft_limiter("FSYNTH", prescale_level, FRAMES_PER_BUFFER)
+        : soft_limiter("FSYNTH", prescale_level, FRAMES_PER_BUFFER),
+          keep_rendering(false)
 {}
 
 bool MidiHandlerFluidsynth::Open(MAYBE_UNUSED const char *conf)
@@ -295,7 +296,7 @@ bool MidiHandlerFluidsynth::Open(MAYBE_UNUSED const char *conf)
 	keep_rendering = true;
 	const auto render = std::bind(&MidiHandlerFluidsynth::Render, this);
 	renderer = std::thread(render);
-	playable.wait_dequeue(play_buffer); // populate the first play buffer
+	play_buffer = playable.Dequeue(); // populate the first play buffer
 
 	// Start playback
 	channel->Enable(true);
@@ -319,10 +320,10 @@ void MidiHandlerFluidsynth::Close()
 
 	// Stop rendering and drain the rings
 	keep_rendering = false;
-	if (!backstock.size_approx())
-		backstock.wait_enqueue(std::move(play_buffer));
-	while (playable.size_approx())
-		playable.wait_dequeue(play_buffer);
+	if (!backstock.Size())
+		backstock.Enqueue(std::move(play_buffer));
+	while (playable.Size())
+		play_buffer = playable.Dequeue();
 
 	// Wait for the rendering thread to finish
 	if (renderer.joinable())
@@ -415,8 +416,8 @@ uint16_t MidiHandlerFluidsynth::GetRemainingFrames()
 		return FRAMES_PER_BUFFER - last_played_frame;
 
 	// Otherwise put the spent buffer in backstock and get the next buffer
-	backstock.wait_enqueue(std::move(play_buffer));
-	playable.wait_dequeue(play_buffer);
+	backstock.Enqueue(std::move(play_buffer));
+	play_buffer = playable.Dequeue();
 	last_played_frame = 0; // reset the frame counter to the beginning
 
 	return FRAMES_PER_BUFFER;
@@ -431,22 +432,22 @@ void MidiHandlerFluidsynth::Render()
 	std::vector<int16_t> playable_buffer(SAMPLES_PER_BUFFER);
 
 	// Populate the backstock using copies of the current buffer.
-	while (backstock.size_approx() < backstock.max_capacity() - 1)
-		backstock.wait_enqueue(playable_buffer);    // copy-in
-	backstock.wait_enqueue(std::move(playable_buffer)); // move the last one
-	assert(backstock.size_approx() == backstock.max_capacity());
+	while (backstock.Size() < backstock.MaxCapacity() - 1)
+		backstock.Enqueue(playable_buffer);
+	backstock.Enqueue(std::move(playable_buffer));
+	assert(backstock.Size() == backstock.MaxCapacity());
 
-	while (keep_rendering) {
+	while (keep_rendering.load()) {
 		fluid_synth_write_float(synth.get(), FRAMES_PER_BUFFER,
 		                        render_buffer.data(), 0, 2,
 		                        render_buffer.data(), 1, 2);
 
 		// Grab the next buffer from backstock and populate it ...
-		backstock.wait_dequeue(playable_buffer);
+		playable_buffer = backstock.Dequeue();
 		soft_limiter.Process(render_buffer, FRAMES_PER_BUFFER,
 		                     playable_buffer);
 		// and then move it into the playable queue
-		playable.wait_enqueue(std::move(playable_buffer));
+		playable.Enqueue(std::move(playable_buffer));
 	}
 }
 
diff --git a/src/midi/midi_fluidsynth.h b/src/midi/midi_fluidsynth.h
index ee97ac5b1..3dcf7f6f1 100644
--- a/src/midi/midi_fluidsynth.h
+++ b/src/midi/midi_fluidsynth.h
@@ -27,13 +27,14 @@
 
 #if C_FLUIDSYNTH
 
+#include <atomic>
 #include <memory>
 #include <vector>
 #include <fluidsynth.h>
 #include <thread>
 
 #include "mixer.h"
-#include "../libs/rwqueue/readerwritercircularbuffer.h"
+#include "rwqueue.h"
 #include "soft_limiter.h"
 
 class MidiHandlerFluidsynth final : public MidiHandler {
@@ -57,8 +58,6 @@ class MidiHandlerFluidsynth final : public MidiHandler {
 	        std::unique_ptr<fluid_settings_t, decltype(&delete_fluid_settings)>;
 	using fsynth_ptr_t = std::unique_ptr<fluid_synth_t, decltype(&delete_fluid_synth)>;
 	using channel_t = std::unique_ptr<MixerChannel, decltype(&MIXER_DelChannel)>;
-	using ring_t = moodycamel::BlockingReaderWriterCircularBuffer<std::vector<int16_t>>;
-	using conditional_t = moodycamel::weak_atomic<bool>;
 
 	fluid_settings_ptr_t settings{nullptr, &delete_fluid_settings};
 	fsynth_ptr_t synth{nullptr, &delete_fluid_synth};
@@ -66,15 +65,15 @@ class MidiHandlerFluidsynth final : public MidiHandler {
 
 	std::vector<int16_t> play_buffer = {};
 	static constexpr auto num_buffers = 8;
-	ring_t playable{num_buffers};
-	ring_t backstock{num_buffers};
+	RWQueue<std::vector<int16_t>> playable{num_buffers};
+	RWQueue<std::vector<int16_t>> backstock{num_buffers};
 
 	std::thread renderer = {};
 	AudioFrame prescale_level = {1.0f, 1.0f};
 	SoftLimiter soft_limiter;
 
 	uint16_t last_played_frame = 0; // relative frame-offset in the play buffer
-	conditional_t keep_rendering = false;
+	std::atomic_bool keep_rendering = {};
 	bool is_open = false;
 };
 

From f7be76ec1a2e3f10ec477f5f41067395a329383c Mon Sep 17 00:00:00 2001
From: kcgen <1557255+kcgen@users.noreply.github.com>
Date: Fri, 26 Feb 2021 15:57:02 -0800
Subject: [PATCH 2/3] Use rwqueue instead of the Moody-queue in MT-32

---
 src/midi/midi_mt32.cpp | 31 ++++++++++++++++---------------
 src/midi/midi_mt32.h   | 11 +++++------
 2 files changed, 21 insertions(+), 21 deletions(-)

diff --git a/src/midi/midi_mt32.cpp b/src/midi/midi_mt32.cpp
index 5964e5daf..37b27b5d4 100644
--- a/src/midi/midi_mt32.cpp
+++ b/src/midi/midi_mt32.cpp
@@ -239,7 +239,8 @@ static mt32emu_report_handler_i get_report_handler_interface()
 }
 
 MidiHandler_mt32::MidiHandler_mt32()
-        : soft_limiter("MT32", limiter_ratio, FRAMES_PER_BUFFER)
+        : soft_limiter("MT32", limiter_ratio, FRAMES_PER_BUFFER),
+          keep_rendering(false)
 {}
 
 bool MidiHandler_mt32::Open(MAYBE_UNUSED const char *conf)
@@ -329,7 +330,7 @@ bool MidiHandler_mt32::Open(MAYBE_UNUSED const char *conf)
 	keep_rendering = true;
 	const auto render = std::bind(&MidiHandler_mt32::Render, this);
 	renderer = std::thread(render);
-	playable.wait_dequeue(play_buffer); // populate the first play buffer
+	play_buffer = playable.Dequeue(); // populate the first play buffer
 
 	// Start playback
 	channel->Enable(true);
@@ -373,10 +374,10 @@ void MidiHandler_mt32::Close()
 
 	// Stop rendering and drain the rings
 	keep_rendering = false;
-	if (!backstock.size_approx())
-		backstock.wait_enqueue(std::move(play_buffer));
-	while (playable.size_approx())
-		playable.wait_dequeue(play_buffer);
+	if (!backstock.Size())
+		backstock.Enqueue(std::move(play_buffer));
+	while (playable.Size())
+		play_buffer = playable.Dequeue();
 
 	// Wait for the rendering thread to finish
 	if (renderer.joinable())
@@ -438,8 +439,8 @@ uint16_t MidiHandler_mt32::GetRemainingFrames()
 		return FRAMES_PER_BUFFER - last_played_frame;
 
 	// Otherwise put the spent buffer in backstock and get the next buffer
-	backstock.wait_enqueue(std::move(play_buffer));
-	playable.wait_dequeue(play_buffer);
+	backstock.Enqueue(std::move(play_buffer));
+	play_buffer = playable.Dequeue();
 	total_buffers_played++;
 	last_played_frame = 0; // reset the frame counter to the beginning
 
@@ -455,20 +456,20 @@ void MidiHandler_mt32::Render()
 	std::vector<int16_t> playable_buffer(SAMPLES_PER_BUFFER);
 
 	// Populate the backstock using copies of the current buffer.
-	while (backstock.size_approx() < backstock.max_capacity() - 1)
-		backstock.wait_enqueue(playable_buffer);    // copy-in
-	backstock.wait_enqueue(std::move(playable_buffer)); // move the last one
-	assert(backstock.size_approx() == backstock.max_capacity());
+	while (backstock.Size() < backstock.MaxCapacity() - 1)
+		backstock.Enqueue(playable_buffer);
+	backstock.Enqueue(std::move(playable_buffer));
+	assert(backstock.Size() == backstock.MaxCapacity());
 
-	while (keep_rendering) {
+	while (keep_rendering.load()) {
 		service->renderFloat(render_buffer.data(), FRAMES_PER_BUFFER);
 
 		// Grab the next buffer from backstock and populate it ...
-		backstock.wait_dequeue(playable_buffer);
+		playable_buffer = backstock.Dequeue();
 		soft_limiter.Process(render_buffer, FRAMES_PER_BUFFER, playable_buffer);
 
 		// and then move it into the playable queue
-		playable.wait_enqueue(std::move(playable_buffer));
+		playable.Enqueue(std::move(playable_buffer));
 	}
 }
 
diff --git a/src/midi/midi_mt32.h b/src/midi/midi_mt32.h
index 49028c894..7d048e72a 100644
--- a/src/midi/midi_mt32.h
+++ b/src/midi/midi_mt32.h
@@ -26,6 +26,7 @@
 
 #if C_MT32EMU
 
+#include <atomic>
 #include <memory>
 #include <thread>
 #include <vector>
@@ -37,14 +38,12 @@
 #endif
 
 #include "mixer.h"
-#include "../libs/rwqueue/readerwritercircularbuffer.h"
+#include "rwqueue.h"
 #include "soft_limiter.h"
 
 class MidiHandler_mt32 final : public MidiHandler {
 private:
-	using ring_t = moodycamel::BlockingReaderWriterCircularBuffer<std::vector<int16_t>>;
 	using channel_t = std::unique_ptr<MixerChannel, decltype(&MIXER_DelChannel)>;
-	using conditional_t = moodycamel::weak_atomic<bool>;
 
 public:
 	using service_t = std::unique_ptr<MT32Emu::Service>;
@@ -70,8 +69,8 @@ class MidiHandler_mt32 final : public MidiHandler {
 
 	std::vector<int16_t> play_buffer = {};
 	static constexpr auto num_buffers = 4;
-	ring_t playable{num_buffers};
-	ring_t backstock{num_buffers};
+	RWQueue<std::vector<int16_t>> playable{num_buffers};
+	RWQueue<std::vector<int16_t>> backstock{num_buffers};
 
 	service_t service{};
 	std::thread renderer{};
@@ -84,7 +83,7 @@ class MidiHandler_mt32 final : public MidiHandler {
 	uint32_t total_buffers_played = 0;
 	uint16_t last_played_frame = 0; // relative frame-offset in the play buffer
 
-	conditional_t keep_rendering = false;
+	std::atomic_bool keep_rendering = {};
 	bool is_open = false;
 };
 

From 5996ca239b948a43a1d6daab0d6bb31305f1cbb8 Mon Sep 17 00:00:00 2001
From: kcgen <1557255+kcgen@users.noreply.github.com>
Date: Wed, 3 Mar 2021 07:58:37 -0800
Subject: [PATCH 3/3] Drop the moodycamel readerwriter queue

---
 src/libs/rwqueue/LICENSE                      |  28 -
 src/libs/rwqueue/README                       | 141 ----
 src/libs/rwqueue/atomicops.h                  | 678 ------------------
 src/libs/rwqueue/readerwritercircularbuffer.h | 288 --------
 tests/meson.build                             |  11 +-
 tests/readerwritercircularbuffer.cpp          | 121 ----
 6 files changed, 5 insertions(+), 1262 deletions(-)
 delete mode 100644 src/libs/rwqueue/LICENSE
 delete mode 100644 src/libs/rwqueue/README
 delete mode 100644 src/libs/rwqueue/atomicops.h
 delete mode 100644 src/libs/rwqueue/readerwritercircularbuffer.h
 delete mode 100644 tests/readerwritercircularbuffer.cpp

diff --git a/src/libs/rwqueue/LICENSE b/src/libs/rwqueue/LICENSE
deleted file mode 100644
index 76d802ecc..000000000
--- a/src/libs/rwqueue/LICENSE
+++ /dev/null
@@ -1,28 +0,0 @@
-This license applies to all the code in this repository except that written by third
-parties, namely the files in benchmarks/ext, which have their own licenses, and Jeff
-Preshing's semaphore implementation (used in the blocking queue) which has a zlib
-license (embedded in atomicops.h).
-
-Simplified BSD License:
-
-Copyright (c) 2013-2015, Cameron Desrochers  
-All rights reserved.
-
-Redistribution and use in source and binary forms, with or without modification,
-are permitted provided that the following conditions are met:
-
-- Redistributions of source code must retain the above copyright notice, this list of
-conditions and the following disclaimer.
-- Redistributions in binary form must reproduce the above copyright notice, this list of
-conditions and the following disclaimer in the documentation and/or other materials
-provided with the distribution.
-
-THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY
-EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
-MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL
-THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
-OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
-HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR
-TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,
-EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
diff --git a/src/libs/rwqueue/README b/src/libs/rwqueue/README
deleted file mode 100644
index 560b70a13..000000000
--- a/src/libs/rwqueue/README
+++ /dev/null
@@ -1,141 +0,0 @@
-# A single-producer, single-consumer lock-free queue for C++
-
-This mini-repository has my very own implementation of a lock-free queue (that I designed from scratch) for C++.
-
-It only supports a two-thread use case (one consuming, and one producing). The threads can't switch roles, though
-you could use this queue completely from a single thread if you wish (but that would sort of defeat the purpose!).
-
-Note: If you need a general-purpose multi-producer, multi-consumer lock free queue, I have [one of those too][mpmc].
-
-
-## Features
-
-- [Blazing fast][benchmarks]
-- Compatible with C++11 (supports moving objects instead of making copies)
-- Fully generic (templated container of any type) -- just like `std::queue`, you never need to allocate memory for elements yourself
-  (which saves you the hassle of writing a lock-free memory manager to hold the elements you're queueing)
-- Allocates memory up front, in contiguous blocks
-- Provides a `try_enqueue` method which is guaranteed never to allocate memory (the queue starts with an initial capacity)
-- Also provides an `enqueue` method which can dynamically grow the size of the queue as needed
-- Also provides `try_emplace`/`emplace` convenience methods
-- Has a blocking version with `wait_dequeue`
-- Completely "wait-free" (no compare-and-swap loop). Enqueue and dequeue are always O(1) (not counting memory allocation)
-- On x86, the memory barriers compile down to no-ops, meaning enqueue and dequeue are just a simple series of loads and stores (and branches)
-
-
-## Use
-
-Simply drop the readerwriterqueue.h and atomicops.h files into your source code and include them :-)
-A modern compiler is required (MSVC2010+, GCC 4.7+, ICC 13+, or any C++11 compliant compiler should work).
-
-Note: If you're using GCC, you really do need GCC 4.7 or above -- [4.6 has a bug][gcc46bug] that prevents the atomic fence primitives
-from working correctly.
-
-Example:
-
-```cpp
-using namespace moodycamel;
-
-ReaderWriterQueue<int> q(100);       // Reserve space for at least 100 elements up front
-
-q.enqueue(17);                       // Will allocate memory if the queue is full
-bool succeeded = q.try_enqueue(18);  // Will only succeed if the queue has an empty slot (never allocates)
-assert(succeeded);
-
-int number;
-succeeded = q.try_dequeue(number);  // Returns false if the queue was empty
-
-assert(succeeded && number == 17);
-
-// You can also peek at the front item of the queue (consumer only)
-int* front = q.peek();
-assert(*front == 18);
-succeeded = q.try_dequeue(number);
-assert(succeeded && number == 18);
-front = q.peek(); 
-assert(front == nullptr);           // Returns nullptr if the queue was empty
-```
-
-The blocking version has the exact same API, with the addition of `wait_dequeue` and
-`wait_dequeue_timed` methods:
-
-```cpp
-BlockingReaderWriterQueue<int> q;
-
-std::thread reader([&]() {
-    int item;
-#if 1
-    for (int i = 0; i != 100; ++i) {
-        // Fully-blocking:
-        q.wait_dequeue(item);
-    }
-#else
-    for (int i = 0; i != 100; ) {
-        // Blocking with timeout
-        if (q.wait_dequeue_timed(item, std::chrono::milliseconds(5)))
-            ++i;
-    }
-#endif
-});
-std::thread writer([&]() {
-    for (int i = 0; i != 100; ++i) {
-        q.enqueue(i);
-        std::this_thread::sleep_for(std::chrono::milliseconds(10));
-    }
-});
-writer.join();
-reader.join();
-
-assert(q.size_approx() == 0);
-```
-    
-Note that `wait_dequeue` will block indefinitely while the queue is empty; this
-means care must be taken to only call `wait_dequeue` if you're sure another element
-will come along eventually, or if the queue has a static lifetime. This is because
-destroying the queue while a thread is waiting on it will invoke undefined behaviour.
-
-## CMake installation
-As an alternative to including the source files in your project directly,
-you can use CMake to install the library in your system's include directory:
-
-```
-mkdir build
-cd build
-cmake ..
-make install
-```
-
-Then, you can include it from your source code:
-```
-#include <readerwriterqueue/readerwriterqueue.h>
-```
-
-## Disclaimers
-
-The queue should only be used on platforms where aligned integer and pointer access is atomic; fortunately, that
-includes all modern processors (e.g. x86/x86-64, ARM, and PowerPC). *Not* for use with a DEC Alpha processor (which has very weak memory ordering) :-)
-
-Note that it's only been tested on x86(-64); if someone has access to other processors I'd love to run some tests on
-anything that's not x86-based.
-
-Finally, I am not an expert. This is my first foray into lock-free programming, and though I'm confident in the code,
-it's possible that there are bugs despite the effort I put into designing and testing this data structure.
-
-Use this code at your own risk; in particular, lock-free programming is a patent minefield, and this code may very
-well violate a pending patent (I haven't looked). It's worth noting that I came up with this algorithm and
-implementation from scratch, independent of any existing lock-free queues.
-
-
-## More info
-
-See the [LICENSE.md][license] file for the license (simplified BSD).
-
-My [blog post][blog] introduces the context that led to this code, and may be of interest if you're curious
-about lock-free programming.
-
-
-[blog]: http://moodycamel.com/blog/2013/a-fast-lock-free-queue-for-c++
-[license]: LICENSE.md
-[benchmarks]: http://moodycamel.com/blog/2013/a-fast-lock-free-queue-for-c++#benchmarks
-[gcc46bug]: http://stackoverflow.com/questions/16429669/stdatomic-thread-fence-has-undefined-reference
-[mpmc]: https://github.com/cameron314/concurrentqueue
diff --git a/src/libs/rwqueue/atomicops.h b/src/libs/rwqueue/atomicops.h
deleted file mode 100644
index 8057c6fe3..000000000
--- a/src/libs/rwqueue/atomicops.h
+++ /dev/null
@@ -1,678 +0,0 @@
-// ©2013-2016 Cameron Desrochers.
-// Distributed under the simplified BSD license (see the license file that
-// should have come with this header).
-// Uses Jeff Preshing's semaphore implementation (under the terms of its
-// separate zlib license, embedded below).
-
-#pragma once
-
-// Provides portable (VC++2010+, Intel ICC 13, GCC 4.7+, and anything C++11 compliant) implementation
-// of low-level memory barriers, plus a few semi-portable utility macros (for inlining and alignment).
-// Also has a basic atomic type (limited to hardware-supported atomics with no memory ordering guarantees).
-// Uses the AE_* prefix for macros (historical reasons), and the "moodycamel" namespace for symbols.
-
-#include <cassert>
-#include <cerrno>
-#include <cstdint>
-#include <ctime>
-#include <type_traits>
-
-// Platform detection
-#if defined(__INTEL_COMPILER)
-#define AE_ICC
-#elif defined(_MSC_VER)
-#define AE_VCPP
-#elif defined(__GNUC__)
-#define AE_GCC
-#endif
-
-#if defined(_M_IA64) || defined(__ia64__)
-#define AE_ARCH_IA64
-#elif defined(_WIN64) || defined(__amd64__) || defined(_M_X64) || defined(__x86_64__)
-#define AE_ARCH_X64
-#elif defined(_M_IX86) || defined(__i386__)
-#define AE_ARCH_X86
-#elif defined(_M_PPC) || defined(__powerpc__)
-#define AE_ARCH_PPC
-#else
-#define AE_ARCH_UNKNOWN
-#endif
-
-
-// AE_UNUSED
-#define AE_UNUSED(x) ((void)x)
-
-// AE_NO_TSAN
-#if defined(__has_feature)
-#if __has_feature(thread_sanitizer)
-#define AE_NO_TSAN __attribute__((no_sanitize("thread")))
-#else
-#define AE_NO_TSAN
-#endif
-#else
-#define AE_NO_TSAN
-#endif
-
-
-// AE_FORCEINLINE
-#if defined(AE_VCPP) || defined(AE_ICC)
-#define AE_FORCEINLINE __forceinline
-#elif defined(AE_GCC)
-//#define AE_FORCEINLINE __attribute__((always_inline)) 
-#define AE_FORCEINLINE inline
-#else
-#define AE_FORCEINLINE inline
-#endif
-
-
-// AE_ALIGN
-#if defined(AE_VCPP) || defined(AE_ICC)
-#define AE_ALIGN(x) __declspec(align(x))
-#elif defined(AE_GCC)
-#define AE_ALIGN(x) __attribute__((aligned(x)))
-#else
-// Assume GCC compliant syntax...
-#define AE_ALIGN(x) __attribute__((aligned(x)))
-#endif
-
-
-// Portable atomic fences implemented below:
-
-namespace moodycamel {
-
-enum memory_order {
-	memory_order_relaxed,
-	memory_order_acquire,
-	memory_order_release,
-	memory_order_acq_rel,
-	memory_order_seq_cst,
-
-	// memory_order_sync: Forces a full sync:
-	// #LoadLoad, #LoadStore, #StoreStore, and most significantly, #StoreLoad
-	memory_order_sync = memory_order_seq_cst
-};
-
-}    // end namespace moodycamel
-
-#if (defined(AE_VCPP) && (_MSC_VER < 1700 || defined(__cplusplus_cli))) || (defined(AE_ICC) && __INTEL_COMPILER < 1600)
-// VS2010 and ICC13 don't support std::atomic_*_fence, implement our own fences
-
-#include <intrin.h>
-
-#if defined(AE_ARCH_X64) || defined(AE_ARCH_X86)
-#define AeFullSync _mm_mfence
-#define AeLiteSync _mm_mfence
-#elif defined(AE_ARCH_IA64)
-#define AeFullSync __mf
-#define AeLiteSync __mf
-#elif defined(AE_ARCH_PPC)
-#include <ppcintrinsics.h>
-#define AeFullSync __sync
-#define AeLiteSync __lwsync
-#endif
-
-
-#ifdef AE_VCPP
-#pragma warning(push)
-#pragma warning(disable: 4365)		// Disable erroneous 'conversion from long to unsigned int, signed/unsigned mismatch' error when using `assert`
-#ifdef __cplusplus_cli
-#pragma managed(push, off)
-#endif
-#endif
-
-namespace moodycamel {
-
-AE_FORCEINLINE void compiler_fence(memory_order order) AE_NO_TSAN
-{
-	switch (order) {
-		case memory_order_relaxed: break;
-		case memory_order_acquire: _ReadBarrier(); break;
-		case memory_order_release: _WriteBarrier(); break;
-		case memory_order_acq_rel: _ReadWriteBarrier(); break;
-		case memory_order_seq_cst: _ReadWriteBarrier(); break;
-		default: assert(false);
-	}
-}
-
-// x86/x64 have a strong memory model -- all loads and stores have
-// acquire and release semantics automatically (so only need compiler
-// barriers for those).
-#if defined(AE_ARCH_X86) || defined(AE_ARCH_X64)
-AE_FORCEINLINE void fence(memory_order order) AE_NO_TSAN
-{
-	switch (order) {
-		case memory_order_relaxed: break;
-		case memory_order_acquire: _ReadBarrier(); break;
-		case memory_order_release: _WriteBarrier(); break;
-		case memory_order_acq_rel: _ReadWriteBarrier(); break;
-		case memory_order_seq_cst:
-			_ReadWriteBarrier();
-			AeFullSync();
-			_ReadWriteBarrier();
-			break;
-		default: assert(false);
-	}
-}
-#else
-AE_FORCEINLINE void fence(memory_order order) AE_NO_TSAN
-{
-	// Non-specialized arch, use heavier memory barriers everywhere just in case :-(
-	switch (order) {
-		case memory_order_relaxed:
-			break;
-		case memory_order_acquire:
-			_ReadBarrier();
-			AeLiteSync();
-			_ReadBarrier();
-			break;
-		case memory_order_release:
-			_WriteBarrier();
-			AeLiteSync();
-			_WriteBarrier();
-			break;
-		case memory_order_acq_rel:
-			_ReadWriteBarrier();
-			AeLiteSync();
-			_ReadWriteBarrier();
-			break;
-		case memory_order_seq_cst:
-			_ReadWriteBarrier();
-			AeFullSync();
-			_ReadWriteBarrier();
-			break;
-		default: assert(false);
-	}
-}
-#endif
-}    // end namespace moodycamel
-#else
-// Use standard library of atomics
-#include <atomic>
-
-namespace moodycamel {
-
-AE_FORCEINLINE void compiler_fence(memory_order order) AE_NO_TSAN
-{
-	switch (order) {
-		case memory_order_relaxed: break;
-		case memory_order_acquire: std::atomic_signal_fence(std::memory_order_acquire); break;
-		case memory_order_release: std::atomic_signal_fence(std::memory_order_release); break;
-		case memory_order_acq_rel: std::atomic_signal_fence(std::memory_order_acq_rel); break;
-		case memory_order_seq_cst: std::atomic_signal_fence(std::memory_order_seq_cst); break;
-		default: assert(false);
-	}
-}
-
-AE_FORCEINLINE void fence(memory_order order) AE_NO_TSAN
-{
-	switch (order) {
-		case memory_order_relaxed: break;
-		case memory_order_acquire: std::atomic_thread_fence(std::memory_order_acquire); break;
-		case memory_order_release: std::atomic_thread_fence(std::memory_order_release); break;
-		case memory_order_acq_rel: std::atomic_thread_fence(std::memory_order_acq_rel); break;
-		case memory_order_seq_cst: std::atomic_thread_fence(std::memory_order_seq_cst); break;
-		default: assert(false);
-	}
-}
-
-}    // end namespace moodycamel
-
-#endif
-
-
-#if !defined(AE_VCPP) || (_MSC_VER >= 1700 && !defined(__cplusplus_cli))
-#define AE_USE_STD_ATOMIC_FOR_WEAK_ATOMIC
-#endif
-
-#ifdef AE_USE_STD_ATOMIC_FOR_WEAK_ATOMIC
-#include <atomic>
-#endif
-#include <utility>
-
-// WARNING: *NOT* A REPLACEMENT FOR std::atomic. READ CAREFULLY:
-// Provides basic support for atomic variables -- no memory ordering guarantees are provided.
-// The guarantee of atomicity is only made for types that already have atomic load and store guarantees
-// at the hardware level -- on most platforms this generally means aligned pointers and integers (only).
-namespace moodycamel {
-template<typename T>
-class weak_atomic
-{
-public:
-	AE_NO_TSAN weak_atomic() : value() { }
-#ifdef AE_VCPP
-#pragma warning(push)
-#pragma warning(disable: 4100)		// Get rid of (erroneous) 'unreferenced formal parameter' warning
-#endif
-	template<typename U> AE_NO_TSAN weak_atomic(U&& x) : value(std::forward<U>(x)) {  }
-#ifdef __cplusplus_cli
-	// Work around bug with universal reference/nullptr combination that only appears when /clr is on
-	AE_NO_TSAN weak_atomic(nullptr_t) : value(nullptr) {  }
-#endif
-	AE_NO_TSAN weak_atomic(weak_atomic const& other) : value(other.load()) {  }
-	AE_NO_TSAN weak_atomic(weak_atomic&& other) : value(std::move(other.load())) {  }
-#ifdef AE_VCPP
-#pragma warning(pop)
-#endif
-
-	AE_FORCEINLINE operator T() const AE_NO_TSAN { return load(); }
-
-	
-#ifndef AE_USE_STD_ATOMIC_FOR_WEAK_ATOMIC
-	template<typename U> AE_FORCEINLINE weak_atomic const& operator=(U&& x) AE_NO_TSAN { value = std::forward<U>(x); return *this; }
-	AE_FORCEINLINE weak_atomic const& operator=(weak_atomic const& other) AE_NO_TSAN { value = other.value; return *this; }
-	
-	AE_FORCEINLINE T load() const AE_NO_TSAN { return value; }
-	
-	AE_FORCEINLINE T fetch_add_acquire(T increment) AE_NO_TSAN
-	{
-#if defined(AE_ARCH_X64) || defined(AE_ARCH_X86)
-		if (sizeof(T) == 4) return _InterlockedExchangeAdd((long volatile*)&value, (long)increment);
-#if defined(_M_AMD64)
-		else if (sizeof(T) == 8) return _InterlockedExchangeAdd64((long long volatile*)&value, (long long)increment);
-#endif
-#else
-#error Unsupported platform
-#endif
-		assert(false && "T must be either a 32 or 64 bit type");
-		return value;
-	}
-	
-	AE_FORCEINLINE T fetch_add_release(T increment) AE_NO_TSAN
-	{
-#if defined(AE_ARCH_X64) || defined(AE_ARCH_X86)
-		if (sizeof(T) == 4) return _InterlockedExchangeAdd((long volatile*)&value, (long)increment);
-#if defined(_M_AMD64)
-		else if (sizeof(T) == 8) return _InterlockedExchangeAdd64((long long volatile*)&value, (long long)increment);
-#endif
-#else
-#error Unsupported platform
-#endif
-		assert(false && "T must be either a 32 or 64 bit type");
-		return value;
-	}
-#else
-	template<typename U>
-	AE_FORCEINLINE weak_atomic const& operator=(U&& x) AE_NO_TSAN
-	{
-		value.store(std::forward<U>(x), std::memory_order_relaxed);
-		return *this;
-	}
-	
-	AE_FORCEINLINE weak_atomic const& operator=(weak_atomic const& other) AE_NO_TSAN
-	{
-		value.store(other.value.load(std::memory_order_relaxed), std::memory_order_relaxed);
-		return *this;
-	}
-
-	AE_FORCEINLINE T load() const AE_NO_TSAN { return value.load(std::memory_order_relaxed); }
-	
-	AE_FORCEINLINE T fetch_add_acquire(T increment) AE_NO_TSAN
-	{
-		return value.fetch_add(increment, std::memory_order_acquire);
-	}
-	
-	AE_FORCEINLINE T fetch_add_release(T increment) AE_NO_TSAN
-	{
-		return value.fetch_add(increment, std::memory_order_release);
-	}
-#endif
-	
-
-private:
-#ifndef AE_USE_STD_ATOMIC_FOR_WEAK_ATOMIC
-	// No std::atomic support, but still need to circumvent compiler optimizations.
-	// `volatile` will make memory access slow, but is guaranteed to be reliable.
-	volatile T value;
-#else
-	std::atomic<T> value;
-#endif
-};
-
-}	// end namespace moodycamel
-
-
-
-// Portable single-producer, single-consumer semaphore below:
-
-#if defined(_WIN32)
-// Avoid including windows.h in a header; we only need a handful of
-// items, so we'll redeclare them here (this is relatively safe since
-// the API generally has to remain stable between Windows versions).
-// I know this is an ugly hack but it still beats polluting the global
-// namespace with thousands of generic names or adding a .cpp for nothing.
-extern "C" {
-	struct _SECURITY_ATTRIBUTES;
-	__declspec(dllimport) void* __stdcall CreateSemaphoreW(_SECURITY_ATTRIBUTES* lpSemaphoreAttributes, long lInitialCount, long lMaximumCount, const wchar_t* lpName);
-	__declspec(dllimport) int __stdcall CloseHandle(void* hObject);
-	__declspec(dllimport) unsigned long __stdcall WaitForSingleObject(void* hHandle, unsigned long dwMilliseconds);
-	__declspec(dllimport) int __stdcall ReleaseSemaphore(void* hSemaphore, long lReleaseCount, long* lpPreviousCount);
-}
-#elif defined(__MACH__)
-#include <mach/mach.h>
-#elif defined(__unix__)
-#include <semaphore.h>
-#endif
-
-namespace moodycamel
-{
-	// Code in the spsc_sema namespace below is an adaptation of Jeff Preshing's
-	// portable + lightweight semaphore implementations, originally from
-	// https://github.com/preshing/cpp11-on-multicore/blob/master/common/sema.h
-	// LICENSE:
-	// Copyright (c) 2015 Jeff Preshing
-	//
-	// This software is provided 'as-is', without any express or implied
-	// warranty. In no event will the authors be held liable for any damages
-	// arising from the use of this software.
-	//
-	// Permission is granted to anyone to use this software for any purpose,
-	// including commercial applications, and to alter it and redistribute it
-	// freely, subject to the following restrictions:
-	//
-	// 1. The origin of this software must not be misrepresented; you must not
-	//    claim that you wrote the original software. If you use this software
-	//    in a product, an acknowledgement in the product documentation would be
-	//    appreciated but is not required.
-	// 2. Altered source versions must be plainly marked as such, and must not be
-	//    misrepresented as being the original software.
-	// 3. This notice may not be removed or altered from any source distribution.
-	namespace spsc_sema
-	{
-#if defined(_WIN32)
-		class Semaphore
-		{
-		private:
-		    void* m_hSema;
-		    
-		    Semaphore(const Semaphore& other);
-		    Semaphore& operator=(const Semaphore& other);
-
-		public:
-		    AE_NO_TSAN Semaphore(int initialCount = 0) : m_hSema()
-		    {
-		        assert(initialCount >= 0);
-		        const long maxLong = 0x7fffffff;
-		        m_hSema = CreateSemaphoreW(nullptr, initialCount, maxLong, nullptr);
-		        assert(m_hSema);
-		    }
-
-		    AE_NO_TSAN ~Semaphore()
-		    {
-		        CloseHandle(m_hSema);
-		    }
-
-		    bool wait() AE_NO_TSAN
-		    {
-		    	const unsigned long infinite = 0xffffffff;
-		        return WaitForSingleObject(m_hSema, infinite) == 0;
-		    }
-
-			bool try_wait() AE_NO_TSAN
-			{
-				return WaitForSingleObject(m_hSema, 0) == 0;
-			}
-
-			bool timed_wait(std::uint64_t usecs) AE_NO_TSAN
-			{
-				return WaitForSingleObject(m_hSema, (unsigned long)(usecs / 1000)) == 0;
-			}
-
-		    void signal(int count = 1) AE_NO_TSAN
-		    {
-		        while (!ReleaseSemaphore(m_hSema, count, nullptr));
-		    }
-		};
-#elif defined(__MACH__)
-		//---------------------------------------------------------
-		// Semaphore (Apple iOS and OSX)
-		// Can't use POSIX semaphores due to http://lists.apple.com/archives/darwin-kernel/2009/Apr/msg00010.html
-		//---------------------------------------------------------
-		class Semaphore
-		{
-		private:
-		    semaphore_t m_sema;
-
-		    Semaphore(const Semaphore& other);
-		    Semaphore& operator=(const Semaphore& other);
-
-		public:
-		    AE_NO_TSAN Semaphore(int initialCount = 0) : m_sema()
-		    {
-		        assert(initialCount >= 0);
-		        kern_return_t rc = semaphore_create(mach_task_self(), &m_sema, SYNC_POLICY_FIFO, initialCount);
-		        assert(rc == KERN_SUCCESS);
-		        AE_UNUSED(rc);
-		    }
-
-		    AE_NO_TSAN ~Semaphore()
-		    {
-		        semaphore_destroy(mach_task_self(), m_sema);
-		    }
-
-		    bool wait() AE_NO_TSAN
-		    {
-		        return semaphore_wait(m_sema) == KERN_SUCCESS;
-		    }
-
-			bool try_wait() AE_NO_TSAN
-			{
-				return timed_wait(0);
-			}
-
-			bool timed_wait(std::uint64_t timeout_usecs) AE_NO_TSAN
-			{
-				mach_timespec_t ts;
-				ts.tv_sec = static_cast<unsigned int>(timeout_usecs / 1000000);
-				ts.tv_nsec = static_cast<int>((timeout_usecs % 1000000) * 1000);
-
-				// added in OSX 10.10: https://developer.apple.com/library/prerelease/mac/documentation/General/Reference/APIDiffsMacOSX10_10SeedDiff/modules/Darwin.html
-				kern_return_t rc = semaphore_timedwait(m_sema, ts);
-				return rc == KERN_SUCCESS;
-			}
-
-		    void signal() AE_NO_TSAN
-		    {
-		        while (semaphore_signal(m_sema) != KERN_SUCCESS);
-		    }
-
-		    void signal(int count) AE_NO_TSAN
-		    {
-		        while (count-- > 0)
-		        {
-		            while (semaphore_signal(m_sema) != KERN_SUCCESS);
-		        }
-		    }
-		};
-#elif defined(__unix__)
-		//---------------------------------------------------------
-		// Semaphore (POSIX, Linux)
-		//---------------------------------------------------------
-		class Semaphore
-		{
-		private:
-		    sem_t m_sema;
-
-		    Semaphore(const Semaphore& other);
-		    Semaphore& operator=(const Semaphore& other);
-
-		public:
-		    AE_NO_TSAN Semaphore(int initialCount = 0) : m_sema()
-		    {
-		        assert(initialCount >= 0);
-		        int rc = sem_init(&m_sema, 0, static_cast<unsigned int>(initialCount));
-		        assert(rc == 0);
-		        AE_UNUSED(rc);
-		    }
-
-		    AE_NO_TSAN ~Semaphore()
-		    {
-		        sem_destroy(&m_sema);
-		    }
-
-		    bool wait() AE_NO_TSAN
-		    {
-		        // http://stackoverflow.com/questions/2013181/gdb-causes-sem-wait-to-fail-with-eintr-error
-		        int rc;
-		        do
-		        {
-		            rc = sem_wait(&m_sema);
-		        }
-		        while (rc == -1 && errno == EINTR);
-		        return rc == 0;
-		    }
-
-			bool try_wait() AE_NO_TSAN
-			{
-				int rc;
-				do {
-					rc = sem_trywait(&m_sema);
-				} while (rc == -1 && errno == EINTR);
-				return rc == 0;
-			}
-
-			bool timed_wait(std::uint64_t usecs) AE_NO_TSAN
-			{
-				struct timespec ts;
-				const int usecs_in_1_sec = 1000000;
-				const int nsecs_in_1_sec = 1000000000;
-				clock_gettime(CLOCK_REALTIME, &ts);
-				ts.tv_sec += static_cast<time_t>(usecs / usecs_in_1_sec);
-				ts.tv_nsec += static_cast<long>(usecs % usecs_in_1_sec) * 1000;
-				// sem_timedwait bombs if you have more than 1e9 in tv_nsec
-				// so we have to clean things up before passing it in
-				if (ts.tv_nsec >= nsecs_in_1_sec) {
-					ts.tv_nsec -= nsecs_in_1_sec;
-					++ts.tv_sec;
-				}
-
-				int rc;
-				do {
-					rc = sem_timedwait(&m_sema, &ts);
-				} while (rc == -1 && errno == EINTR);
-				return rc == 0;
-			}
-
-		    void signal() AE_NO_TSAN
-		    {
-		        while (sem_post(&m_sema) == -1);
-		    }
-
-		    void signal(int count) AE_NO_TSAN
-		    {
-		        while (count-- > 0)
-		        {
-		            while (sem_post(&m_sema) == -1);
-		        }
-		    }
-		};
-#else
-#error Unsupported platform! (No semaphore wrapper available)
-#endif
-
-		//---------------------------------------------------------
-		// LightweightSemaphore
-		//---------------------------------------------------------
-		class LightweightSemaphore
-		{
-		public:
-			typedef std::make_signed<std::size_t>::type ssize_t;
-			
-		private:
-		    weak_atomic<ssize_t> m_count;
-		    Semaphore m_sema;
-
-		    bool waitWithPartialSpinning(std::int64_t timeout_usecs = -1) AE_NO_TSAN
-		    {
-		        ssize_t oldCount;
-		        // Is there a better way to set the initial spin count?
-		        // If we lower it to 1000, testBenaphore becomes 15x slower on my Core i7-5930K Windows PC,
-		        // as threads start hitting the kernel semaphore.
-		        int spin = 1024;
-		        while (--spin >= 0)
-		        {
-		            if (m_count.load() > 0)
-		            {
-		                m_count.fetch_add_acquire(-1);
-		                return true;
-		            }
-		            compiler_fence(memory_order_acquire);     // Prevent the compiler from collapsing the loop.
-		        }
-		        oldCount = m_count.fetch_add_acquire(-1);
-				if (oldCount > 0)
-					return true;
-		        if (timeout_usecs < 0)
-				{
-					if (m_sema.wait())
-						return true;
-				}
-				if (timeout_usecs > 0 && m_sema.timed_wait(static_cast<uint64_t>(timeout_usecs)))
-					return true;
-				// At this point, we've timed out waiting for the semaphore, but the
-				// count is still decremented indicating we may still be waiting on
-				// it. So we have to re-adjust the count, but only if the semaphore
-				// wasn't signaled enough times for us too since then. If it was, we
-				// need to release the semaphore too.
-				while (true)
-				{
-					oldCount = m_count.fetch_add_release(1);
-					if (oldCount < 0)
-						return false;    // successfully restored things to the way they were
-					// Oh, the producer thread just signaled the semaphore after all. Try again:
-					oldCount = m_count.fetch_add_acquire(-1);
-					if (oldCount > 0 && m_sema.try_wait())
-						return true;
-				}
-		    }
-
-		public:
-		    AE_NO_TSAN LightweightSemaphore(ssize_t initialCount = 0) : m_count(initialCount), m_sema()
-		    {
-		        assert(initialCount >= 0);
-		    }
-
-		    bool tryWait() AE_NO_TSAN
-		    {
-		        if (m_count.load() > 0)
-		        {
-		        	m_count.fetch_add_acquire(-1);
-		        	return true;
-		        }
-		        return false;
-		    }
-
-		    bool wait() AE_NO_TSAN
-		    {
-		        return tryWait() || waitWithPartialSpinning();
-		    }
-
-			bool wait(std::int64_t timeout_usecs) AE_NO_TSAN
-			{
-				return tryWait() || waitWithPartialSpinning(timeout_usecs);
-			}
-
-		    void signal(ssize_t count = 1) AE_NO_TSAN
-		    {
-		    	assert(count >= 0);
-		        ssize_t oldCount = m_count.fetch_add_release(count);
-		        assert(oldCount >= -1);
-		        if (oldCount < 0)
-		        {
-		            m_sema.signal(1);
-		        }
-		    }
-		    
-		    std::size_t availableApprox() const AE_NO_TSAN
-		    {
-		    	ssize_t count = m_count.load();
-		    	return count > 0 ? static_cast<std::size_t>(count) : 0;
-		    }
-		};
-	}	// end namespace spsc_sema
-}	// end namespace moodycamel
-
-#if defined(AE_VCPP) && (_MSC_VER < 1700 || defined(__cplusplus_cli))
-#pragma warning(pop)
-#ifdef __cplusplus_cli
-#pragma managed(pop)
-#endif
-#endif
diff --git a/src/libs/rwqueue/readerwritercircularbuffer.h b/src/libs/rwqueue/readerwritercircularbuffer.h
deleted file mode 100644
index 284957820..000000000
--- a/src/libs/rwqueue/readerwritercircularbuffer.h
+++ /dev/null
@@ -1,288 +0,0 @@
-// ©2020 Cameron Desrochers.
-// Distributed under the simplified BSD license (see the license file that
-// should have come with this header).
-
-// Provides a C++11 implementation of a single-producer, single-consumer wait-free concurrent
-// circular buffer (fixed-size queue).
-
-#pragma once
-
-#include <cassert>
-#include <chrono>
-#include <cstdint>
-#include <cstdlib>
-#include <memory>
-#include <utility>
-
-// Note that this implementation is fully modern C++11 (not compatible with old MSVC versions)
-// but we still include atomicops.h for its LightweightSemaphore implementation.
-#include "atomicops.h"
-
-#ifndef MOODYCAMEL_CACHE_LINE_SIZE
-#define MOODYCAMEL_CACHE_LINE_SIZE 64
-#endif
-
-namespace moodycamel {
-
-template<typename T>
-class BlockingReaderWriterCircularBuffer
-{
-public:
-	typedef T value_type;
-
-public:
-	explicit BlockingReaderWriterCircularBuffer(std::size_t capacity)
-		: maxcap(capacity), mask(), rawData(), data(),
-		slots(new spsc_sema::LightweightSemaphore(static_cast<spsc_sema::LightweightSemaphore::ssize_t>(capacity))),
-		items(new spsc_sema::LightweightSemaphore(0)),
-		nextSlot(0), nextItem(0)
-	{
-		// Round capacity up to power of two to compute modulo mask.
-		// Adapted from http://graphics.stanford.edu/~seander/bithacks.html#RoundUpPowerOf2
-		--capacity;
-		capacity |= capacity >> 1;
-		capacity |= capacity >> 2;
-		capacity |= capacity >> 4;
-		for (std::size_t i = 1; i < sizeof(std::size_t); i <<= 1)
-			capacity |= capacity >> (i << 3);
-		mask = capacity++;
-		rawData = static_cast<char*>(std::malloc(capacity * sizeof(T) + std::alignment_of<T>::value - 1));
-		data = align_for<T>(rawData);
-	}
-
-	BlockingReaderWriterCircularBuffer(BlockingReaderWriterCircularBuffer&& other)
-		: maxcap(0), mask(0), rawData(nullptr), data(nullptr),
-		slots(new spsc_sema::LightweightSemaphore(0)),
-		items(new spsc_sema::LightweightSemaphore(0)),
-		nextSlot(), nextItem()
-	{
-		swap(other);
-	}
-
-	BlockingReaderWriterCircularBuffer(BlockingReaderWriterCircularBuffer const&) = delete;
-
-	// Note: The queue should not be accessed concurrently while it's
-	// being deleted. It's up to the user to synchronize this.
-	~BlockingReaderWriterCircularBuffer()
-	{
-		for (std::size_t i = 0, n = items->availableApprox(); i != n; ++i)
-			reinterpret_cast<T*>(data)[(nextItem + i) & mask].~T();
-		std::free(rawData);
-	}
-
-	BlockingReaderWriterCircularBuffer& operator=(BlockingReaderWriterCircularBuffer&& other) noexcept
-	{
-		swap(other);
-		return *this;
-	}
-
-	BlockingReaderWriterCircularBuffer& operator=(BlockingReaderWriterCircularBuffer const&) = delete;
-
-	// Swaps the contents of this buffer with the contents of another.
-	// Not thread-safe.
-	void swap(BlockingReaderWriterCircularBuffer& other) noexcept
-	{
-		std::swap(maxcap, other.maxcap);
-		std::swap(mask, other.mask);
-		std::swap(rawData, other.rawData);
-		std::swap(data, other.data);
-		std::swap(slots, other.slots);
-		std::swap(items, other.items);
-		std::swap(nextSlot, other.nextSlot);
-		std::swap(nextItem, other.nextItem);
-	}
-
-	// Enqueues a single item (by copying it).
-	// Fails if not enough room to enqueue.
-	// Thread-safe when called by producer thread.
-	// No exception guarantee (state will be corrupted) if constructor of T throws.
-	bool try_enqueue(T const& item)
-	{
-		if (!slots->tryWait())
-			return false;
-		inner_enqueue(item);
-		return true;
-	}
-
-	// Enqueues a single item (by moving it, if possible).
-	// Fails if not enough room to enqueue.
-	// Thread-safe when called by producer thread.
-	// No exception guarantee (state will be corrupted) if constructor of T throws.
-	bool try_enqueue(T&& item)
-	{
-		if (!slots->tryWait())
-			return false;
-		inner_enqueue(std::move(item));
-		return true;
-	}
-
-	// Blocks the current thread until there's enough space to enqueue the given item,
-	// then enqueues it (via copy).
-	// Thread-safe when called by producer thread.
-	// No exception guarantee (state will be corrupted) if constructor of T throws.
-	void wait_enqueue(T const& item)
-	{
-		while (!slots->wait());
-		inner_enqueue(item);
-	}
-
-	// Blocks the current thread until there's enough space to enqueue the given item,
-	// then enqueues it (via move, if possible).
-	// Thread-safe when called by producer thread.
-	// No exception guarantee (state will be corrupted) if constructor of T throws.
-	void wait_enqueue(T&& item)
-	{
-		while (!slots->wait());
-		inner_enqueue(std::move(item));
-	}
-
-	// Blocks the current thread until there's enough space to enqueue the given item,
-	// or the timeout expires. Returns false without enqueueing the item if the timeout
-	// expires, otherwise enqueues the item (via copy) and returns true.
-	// Thread-safe when called by producer thread.
-	// No exception guarantee (state will be corrupted) if constructor of T throws.
-	bool wait_enqueue_timed(T const& item, std::int64_t timeout_usecs)
-	{
-		if (!slots->wait(timeout_usecs))
-			return false;
-		inner_enqueue(item);
-		return true;
-	}
-
-	// Blocks the current thread until there's enough space to enqueue the given item,
-	// or the timeout expires. Returns false without enqueueing the item if the timeout
-	// expires, otherwise enqueues the item (via move, if possible) and returns true.
-	// Thread-safe when called by producer thread.
-	// No exception guarantee (state will be corrupted) if constructor of T throws.
-	bool wait_enqueue_timed(T&& item, std::int64_t timeout_usecs)
-	{
-		if (!slots->wait(timeout_usecs))
-			return false;
-		inner_enqueue(std::move(item));
-		return true;
-	}
-
-	// Blocks the current thread until there's enough space to enqueue the given item,
-	// or the timeout expires. Returns false without enqueueing the item if the timeout
-	// expires, otherwise enqueues the item (via copy) and returns true.
-	// Thread-safe when called by producer thread.
-	// No exception guarantee (state will be corrupted) if constructor of T throws.
-	template<typename Rep, typename Period>
-	inline bool wait_enqueue_timed(T const& item, std::chrono::duration<Rep, Period> const& timeout)
-	{
-		return wait_enqueue_timed(item, std::chrono::duration_cast<std::chrono::microseconds>(timeout).count());
-	}
-
-	// Blocks the current thread until there's enough space to enqueue the given item,
-	// or the timeout expires. Returns false without enqueueing the item if the timeout
-	// expires, otherwise enqueues the item (via move, if possible) and returns true.
-	// Thread-safe when called by producer thread.
-	// No exception guarantee (state will be corrupted) if constructor of T throws.
-	template<typename Rep, typename Period>
-	inline bool wait_enqueue_timed(T&& item, std::chrono::duration<Rep, Period> const& timeout)
-	{
-		return wait_enqueue_timed(std::move(item), std::chrono::duration_cast<std::chrono::microseconds>(timeout).count());
-	}
-
-	// Attempts to dequeue a single item.
-	// Returns false if the buffer is empty.
-	// Thread-safe when called by consumer thread.
-	// No exception guarantee (state will be corrupted) if assignment operator of U throws.
-	template<typename U>
-	bool try_dequeue(U& item)
-	{
-		if (!items->tryWait())
-			return false;
-		inner_dequeue(item);
-		return true;
-	}
-
-	// Blocks the current thread until there's something to dequeue, then dequeues it.
-	// Thread-safe when called by consumer thread.
-	// No exception guarantee (state will be corrupted) if assignment operator of U throws.
-	template<typename U>
-	void wait_dequeue(U& item)
-	{
-		while (!items->wait());
-		inner_dequeue(item);
-	}
-
-	// Blocks the current thread until either there's something to dequeue
-	// or the timeout expires. Returns false without setting `item` if the
-	// timeout expires, otherwise assigns to `item` and returns true.
-	// Thread-safe when called by consumer thread.
-	// No exception guarantee (state will be corrupted) if assignment operator of U throws.
-	template<typename U>
-	bool wait_dequeue_timed(U& item, std::int64_t timeout_usecs)
-	{
-		if (!items->wait(timeout_usecs))
-			return false;
-		inner_dequeue(item);
-		return true;
-	}
-
-	// Blocks the current thread until either there's something to dequeue
-	// or the timeout expires. Returns false without setting `item` if the
-	// timeout expires, otherwise assigns to `item` and returns true.
-	// Thread-safe when called by consumer thread.
-	// No exception guarantee (state will be corrupted) if assignment operator of U throws.
-	template<typename U, typename Rep, typename Period>
-	inline bool wait_dequeue_timed(U& item, std::chrono::duration<Rep, Period> const& timeout)
-	{
-		return wait_dequeue_timed(item, std::chrono::duration_cast<std::chrono::microseconds>(timeout).count());
-	}
-
-	// Returns a (possibly outdated) snapshot of the total number of elements currently in the buffer.
-	// Thread-safe.
-	inline std::size_t size_approx() const
-	{
-		return items->availableApprox();
-	}
-
-	// Returns the maximum number of elements that this circular buffer can hold at once.
-	// Thread-safe.
-	inline std::size_t max_capacity() const
-	{
-		return maxcap;
-	}
-
-private:
-	template<typename U>
-	void inner_enqueue(U&& item)
-	{
-		std::size_t i = nextSlot++;
-		new (reinterpret_cast<T*>(data) + (i & mask)) T(std::forward<U>(item));
-		items->signal();
-	}
-
-	template<typename U>
-	void inner_dequeue(U& item)
-	{
-		std::size_t i = nextItem++;
-		T& element = reinterpret_cast<T*>(data)[i & mask];
-		item = std::move(element);
-		element.~T();
-		slots->signal();
-	}
-
-	template<typename U>
-	static inline char* align_for(char* ptr)
-	{
-		const std::size_t alignment = std::alignment_of<U>::value;
-		return ptr + (alignment - (reinterpret_cast<std::uintptr_t>(ptr) % alignment)) % alignment;
-	}
-
-private:
-	std::size_t maxcap;                           // actual (non-power-of-two) capacity
-	std::size_t mask;                             // circular buffer capacity mask (for cheap modulo)
-	char* rawData;                                // raw circular buffer memory
-	char* data;                                   // circular buffer memory aligned to element alignment
-	std::unique_ptr<spsc_sema::LightweightSemaphore> slots;  // number of slots currently free
-	std::unique_ptr<spsc_sema::LightweightSemaphore> items;  // number of elements currently enqueued
-	char cachelineFiller0[MOODYCAMEL_CACHE_LINE_SIZE - sizeof(char*) * 2 - sizeof(std::size_t) * 2 - sizeof(std::unique_ptr<spsc_sema::LightweightSemaphore>) * 2];
-	std::size_t nextSlot;                         // index of next free slot to enqueue into
-	char cachelineFiller1[MOODYCAMEL_CACHE_LINE_SIZE - sizeof(std::size_t)];
-	std::size_t nextItem;                         // index of next element to dequeue from
-};
-
-}
diff --git a/tests/meson.build b/tests/meson.build
index d58573fbb..a5589e670 100644
--- a/tests/meson.build
+++ b/tests/meson.build
@@ -43,12 +43,11 @@ test('gtest fs_utils', fs_utils,
 # other unit tests
 #
 unit_tests = [
-  {'name' : 'readerwritercircularbuffer', 'deps' : []},
-  {'name' : 'rwqueue',                    'deps' : [libmisc_dep]},
-  {'name' : 'soft_limiter',               'deps' : [sdl2_dep, libmisc_dep]},
-  {'name' : 'string_utils',               'deps' : []},
-  {'name' : 'setup',                      'deps' : [sdl2_dep, libmisc_dep]},
-  {'name' : 'support',                    'deps' : [sdl2_dep, libmisc_dep]},
+  {'name' : 'rwqueue',      'deps' : [libmisc_dep]},
+  {'name' : 'soft_limiter', 'deps' : [sdl2_dep, libmisc_dep]},
+  {'name' : 'string_utils', 'deps' : []},
+  {'name' : 'setup',        'deps' : [sdl2_dep, libmisc_dep]},
+  {'name' : 'support',      'deps' : [sdl2_dep, libmisc_dep]},
 ]
 
 foreach ut : unit_tests
diff --git a/tests/readerwritercircularbuffer.cpp b/tests/readerwritercircularbuffer.cpp
deleted file mode 100644
index fae1c5e07..000000000
--- a/tests/readerwritercircularbuffer.cpp
+++ /dev/null
@@ -1,121 +0,0 @@
-/*
- *  SPDX-License-Identifier: GPL-2.0-or-later
- *
- *  Copyright (C) 2021       The DOSBox Staging Team
- *  Copyright (C) 2020-2021  Cameron Desrochers
- *
- *  This program is free software; you can redistribute it and/or modify
- *  it under the terms of the GNU General Public License as published by
- *  the Free Software Foundation; either version 2 of the License, or
- *  (at your option) any later version.
- *
- *  This program is distributed in the hope that it will be useful,
- *  but WITHOUT ANY WARRANTY; without even the implied warranty of
- *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- *  GNU General Public License for more details.
- *
- *  You should have received a copy of the GNU General Public License along
- *  with this program; if not, write to the Free Software Foundation, Inc.,
- *  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.
- */
-
-// Unit tests for moodycamel::ReaderWriterCircularBuffer
-
-#include "../src/libs/rwqueue/readerwritercircularbuffer.h"
-
-#include <gtest/gtest.h>
-
-#include <cstdio>
-#include <thread>
-
-namespace {
-using namespace moodycamel;
-
-TEST(ReaderWriterCircularBuffer, EnqueueDequeue)
-{
-	BlockingReaderWriterCircularBuffer<int> q(65);
-	for (int iteration = 0; iteration != 128;
-	     ++iteration) { // check there's no problem with mismatch
-		            // between nominal and allocated capacity
-		EXPECT_EQ(q.max_capacity(), 65);
-		EXPECT_EQ(q.size_approx(), 0);
-		EXPECT_TRUE(q.try_enqueue(0));
-		EXPECT_EQ(q.max_capacity(), 65);
-		EXPECT_EQ(q.size_approx(), 1);
-		for (int i = 1; i != 65; ++i)
-			q.wait_enqueue(i);
-		EXPECT_EQ(q.size_approx(), 65);
-		EXPECT_FALSE(q.try_enqueue(65));
-
-		// Basic dequeue
-		int item;
-		EXPECT_TRUE(q.try_dequeue(item));
-		EXPECT_EQ(item, 0);
-		for (int i = 1; i != 65; ++i) {
-			q.wait_dequeue(item);
-			EXPECT_EQ(item, i);
-		}
-		EXPECT_FALSE(q.try_dequeue(item));
-		EXPECT_FALSE(q.wait_dequeue_timed(item, 1));
-		EXPECT_EQ(item, 64);
-	}
-}
-
-TEST(ReaderWriterCircularBuffer, ZeroCapacity)
-{
-	// Zero capacity
-	BlockingReaderWriterCircularBuffer<int> q(0);
-	EXPECT_EQ(q.max_capacity(), 0);
-	EXPECT_FALSE(q.try_enqueue(1));
-	EXPECT_FALSE(q.wait_enqueue_timed(1, 0));
-}
-
-void consume(BlockingReaderWriterCircularBuffer<int> *q,
-             const size_t *max_depth,
-             weak_atomic<bool> *got_mismatch)
-{
-	int item;
-	for (int i = 0; i != 1000000; ++i) {
-		EXPECT_TRUE(q->size_approx() <= *max_depth);
-		q->wait_dequeue(item);
-		if (item != i && got_mismatch->load() == false) {
-			*got_mismatch = true;
-		}
-	}
-	// printf("exiting consumer thread on item %d\n", item);
-}
-
-void produce(BlockingReaderWriterCircularBuffer<int> *q, const size_t *max_depth)
-{
-	for (int i = 0; i != 1000000; ++i) {
-		q->wait_enqueue(i);
-		EXPECT_TRUE(q->size_approx() <= *max_depth);
-	}
-	// printf("exiting producer thread\n");
-}
-
-TEST(ReaderWriterCircularBuffer, BoundedAsyncProduceAndConsume)
-{
-	const size_t max_depth = 8;
-	weak_atomic<bool> got_mismatch = false;
-
-	BlockingReaderWriterCircularBuffer<int> q(max_depth);
-
-	std::thread writer(produce, &q, &max_depth);
-	std::thread reader(consume, &q, &max_depth, &got_mismatch);
-
-	writer.join();
-	reader.join();
-
-	// Make sure we've consumed all produced items and the queue is empty
-	EXPECT_EQ(q.size_approx(), 0);
-
-	// Make sure there wasn't a single out-of-sequence item consumed
-	EXPECT_FALSE(got_mismatch.load());
-
-	// Confirm both threads report as terminated
-	EXPECT_FALSE(reader.joinable());
-	EXPECT_FALSE(writer.joinable());
-}
-
-} // namespace
